<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="sv" xml:lang="sv">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>02-tokens</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <link rel="stylesheet" href="css/book.css" />
</head>
<body>
<h1 class="chapter" id="lego-för-språk-hur-ain-stavar">Lego för språk:
Hur AI:n stavar</h1>
<div class="chapter-opening">
<p class="chapter-number">
Kapitel 2: Tokens
</p>
<p><img src="../assets/images/chapter-02.png" /></p>
<div class="chapter-ingress">
<p><em>En token är som en Lego-bit – den minsta byggstenen som AI:n
använder för att förstå och bygga text.</em></p>
</div>
</div>
<div style="page-break-after: always;">

</div>
<p>Du är fem år och lär dig läsa. Fingret följer bokstäverna: K-A-T-T.
Fyra ljud. Ett ord. En katt.</p>
<p>Men vänta. Vad händer när ordet blir längre? “Kattunge”? Då är det
inte lika självklart längre. Katt-unge? Ka-ttunge? Kat-tun-ge?</p>
<p>Vuxna tänker sällan på det, men vi delar automatiskt upp långa ord i
hanterbara bitar. Vi <em>tokeniserar</em> språket utan att tänka på
det.</p>
<p>AI:n gör samma sak – fast på sitt eget, märkliga sätt.</p>
<h2 id="bryggan-till-ai">Bryggan till AI</h2>
<p>En språkmodell som GPT eller Claude läser inte text som du gör. Den
ser inte ord. Den ser inte ens bokstäver, egentligen. Den ser
<em>tokens</em> – bitar av text som den brutit ner för att kunna
bearbeta.</p>
<p>Tänk på det som Lego. När du bygger ett Lego-hus ser du helheten:
väggar, tak, dörr. Men allt är uppbyggt av små, standardiserade bitar.
Vissa bitar är vanliga och används överallt. Andra är specialbitar för
specifika situationer.</p>
<p>Tokens fungerar likadant. Vanliga ord som “the”, “is” och “cat” blir
en enda token – en hel Lego-bit. Men ovanliga eller sammansatta ord
delas upp i mindre bitar som modellen redan känner igen.</p>
<h2 id="hur-uppdelningen-går-till">Hur uppdelningen går till</h2>
<p>Låt oss ta ett konkret exempel. Ordet “otrolig” kan se ut så här för
en AI:</p>
<p><strong>Människan ser</strong>: otrolig</p>
<p><strong>AI:n ser</strong>: [“o”, “tro”, “lig”] – tre tokens</p>
<p>Det beror på att AI:n under sin träning lärde sig att “tro” är en
vanlig sekvens, “lig” är en vanlig ändelse, och “o” som prefix dyker upp
ofta. Genom att kombinera dessa byggstenar kan den hantera ord den
aldrig sett förut.</p>
<p>Tumregeln för engelska är att en token motsvarar ungefär tre
fjärdedelar av ett ord. Men – och detta är viktigt – regeln gäller inte
för alla språk.</p>
<h2 id="språkets-orättvisa">Språkets orättvisa</h2>
<p>Här avslöjar tokens något obehagligt om hur AI byggs.</p>
<p>Engelska är extremt gynnat. De flesta språkmodeller tränas på enorma
mängder engelsk text, och deras tokenisering är designad för engelska
först.</p>
<p>Konsekvensen? Ett svenskt ord kan kräva dubbelt så många tokens som
dess engelska motsvarighet. Tamil eller telugu kan kräva upp till
<em>tio gånger</em> fler tokens för samma information.</p>
<p>Det är som om vissa språk måste bygga med mikro-Lego medan andra får
stora, bekväma bitar.</p>
<p>I praktiken betyder detta: - AI:n “tänker kortare” på andra språk än
engelska (context window fylls snabbare) - Det kostar mer att använda AI
på vissa språk - Kvaliteten kan bli sämre när varje ord kräver fler
bearbetningssteg</p>
<h2 id="varför-inte-bara-använda-ord">Varför inte bara använda ord?</h2>
<p>En rimlig fråga: varför gör man det så komplicerat? Varför inte bara
låta AI:n läsa ord för ord?</p>
<p>Svaret handlar om flexibilitet och effektivitet.</p>
<p>Om AI:n bara förstod hela ord skulle den stå handfallen inför nya
ord. Första gången någon skriver “tweetstorm” eller “covidtrött” skulle
modellen bara se: [OKÄNT ORD]. Men med tokens kan den bryta ner det:
[“tweet”, “storm”] eller [“covid”, “trött”] – komponenter den känner
igen.</p>
<p>Det är som skillnaden mellan att bara kunna rita färdiga figurer och
att kunna teckna fritt. Med byggstenar blir du kreativ.</p>
<h2 id="den-matematiska-hemligheten">Den matematiska hemligheten</h2>
<p>Bakom kulisserna händer något fascinerande. Varje token omvandlas
till en lång rad siffror – en matematisk position i ett enormt rum av
betydelser. Ordet “kung” kanske blir: [0.23, -0.45, 0.87, 0.12, …] och
så vidare i hundratals dimensioner.</p>
<p>AI:n “läser” aldrig text. Den navigerar i ett matematiskt landskap
där liknande betydelser ligger nära varandra.</p>
<p>Men det är en annan historia. Det vi behöver förstå här är att tokens
är <em>porten in</em> – det första steget där mänskligt språk översätts
till något en dator kan arbeta med.</p>
<h2 id="varför-det-spelar-roll">Varför det spelar roll</h2>
<p>Förståelsen av tokens förklarar flera saker som annars verkar
mystiska:</p>
<p><strong>“Varför kostar långa svar mer?”</strong> AI-tjänster tar ofta
betalt per token. Fler tokens = högre kostnad.</p>
<p><strong>“Varför är AI sämre på svenska än engelska?”</strong> Svenska
kräver fler tokens för samma innehåll, vilket gör bearbetningen mindre
effektiv.</p>
<p><strong>“Varför har AI svårt med konstiga stavningar?”</strong>
“Heeeeej” blir många fler tokens än “Hej” – varje extra ‘e’ kan bli en
separat token.</p>
<p><strong>“Varför kan AI ibland inte räkna bokstäver?”</strong> När du
frågar “hur många r finns i ‘jordgubbe’?” ser AI:n inte bokstäver – den
ser tokens. Och “jordgubbe” har brutits ner till bitar som inte
nödvändigtvis följer bokstavsgränserna.</p>
<h2 id="analogins-gränser">Analogins gränser</h2>
<p>Det finns en viktig skillnad mellan Lego och tokens.</p>
<p>Lego-bitar är designade med avsikt. Någon har tänkt: “Den här biten
ska vara ett hjul, den här ett fönster.”</p>
<p>Tokens är statistiska. De uppstår ur mönster i träningsdatan – vilka
teckenföljder som förekommer ofta tillsammans. Det finns ingen djupare
logik, ingen förståelse för vad bitarna “betyder”. Det är ren
matematik.</p>
<p>En token kan vara ett helt ord, halva ett ord, eller en meningslös
sekvens av tecken – allt beror på vad som var statistiskt effektivt att
lära sig.</p>
<p>Det är som om Lego-bitarna designat sig själva baserat på vad barn
oftast bygger, utan att någon människa fattade besluten.</p>
<h2 id="slutord">Slutord</h2>
<p>Nästa gång du chattar med en AI, tänk på att dina ord passerar genom
en märklig förvandling innan de når fram.</p>
<p>“Kan du hjälpa mig förstå kvantfysik?”</p>
<p>Blir kanske: [“Kan”, ” du”, ” hjälp”, “a”, ” mig”, ” för”, “stå”, ”
kvant”, “fys”, “ik”, “?”]</p>
<p>Varje bit en Lego-kloss. Varje kloss en position i ett matematiskt
universum. Och någonstans i det universumet försöker AI:n lista ut vad
du menar.</p>
<p>Det är inte magi. Men det är inte heller riktigt läsning.</p>
<p>Det är något helt nytt.</p>
<h2 id="sammanfattning">Sammanfattning</h2>
<p><strong>AI-koncept</strong>: Tokens<br /> <strong>Mänsklig
motsvarighet</strong>: Lego-bitar / stavelser<br /> <strong>Kom
ihåg</strong>: AI:n läser inte ord – den bygger med bitar av text, och
vissa språk får mindre bitar än andra.</p>
<div style="page-break-after: always;">

</div>
</body>
</html>
